{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bochamm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import time as timer\n",
    "\n",
    "\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import qmc\n",
    "from sloscillations import frequencies, mixed_modes_utils\n",
    "#from tqdm import tqdm\n",
    "#from taco.rotation import rotation_utils\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "from turbo import Turbo1, TurboM\n",
    "from turbo.utils import from_unit_cube, latin_hypercube, to_unit_cube\n",
    "from typing import Optional\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(kic):\n",
    "    summary = pd.read_csv(f'../../TACO_benchmarking/data/intermediate/{str(kic).zfill(9)}/summary.csv')\n",
    "    #pds = pd.read_csv('../../TACO_benchmarking/data/intermediate/002283721/pds_bgr.csv')#\n",
    "    pds = pd.read_csv(f'../../TACO_benchmarking/data/intermediate/{str(kic).zfill(9)}/pds_bgr.csv')\n",
    "    #peaks = pd.read_csv('../../TACO_benchmarking/data/intermediate/011353313/peaksMLE.csv')#/\n",
    "    peaks = pd.read_csv(f'../../TACO_benchmarking/data/intermediate/{str(kic).zfill(9)}/peaksMLE.csv')\n",
    "\n",
    "    # Only keep pds around oscillations\n",
    "    pds = pds.loc[abs(pds['frequency'].values - summary['numax'].values) < 3 * summary['sigmaEnv'].values, ]\n",
    "\n",
    "    # # If ΔΠ1 is in mega seconds then convert to seconds\n",
    "    # if summary['DeltaPi1'].values < 1:\n",
    "    #     summary['DeltaPi1'] *= 1e6\n",
    "\n",
    "    # Read in and filter peaks file to be within +/-3 sigmaEnv of numax\n",
    "    peaks = peaks.loc[abs(peaks.frequency.values - summary.numax.values) < 3*summary.sigmaEnv.values, ]\n",
    "\n",
    "    # Split the peaks in the l=0,2,3 peaks (which have been already identified)\n",
    "    # and the rest, which should hopefully be unidentified l=3\n",
    "    l023_peaks = peaks.loc[(peaks.l == 0) | (peaks.l == 2) | (peaks.l == 3), ]\n",
    "    l0_peaks = peaks.loc[(peaks.l==0), ]\n",
    "    l1_peaks = peaks.loc[(peaks.l == 1) | (np.isfinite(peaks.l) == False)]  \n",
    "    \n",
    "    # Divide the data through by the model of the l=0,2 modes\n",
    "    pds_l023_removed = pds.assign(power = pds.power / bochamm.utils.fit_model(pds, l023_peaks))\n",
    "    return summary, pds, peaks, pds_l023_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_RGB_or_RC(pds_l023_removed, freqs):\n",
    "    # RGB run\n",
    "    f, PSD_LS = bochamm.utils.compute_PS_PS(pds_l023_removed.frequency.values, pds_l023_removed.power.values, \n",
    "                                            bochamm.utils.DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu), \n",
    "                                            0.15, freqs,\n",
    "                                            lower_tau_lim=25, upper_tau_lim=200) \n",
    "    rgb_dpi1_guess = (1/f)[np.argmax(PSD_LS)]\n",
    "    rgb_dpi1_max = np.max(PSD_LS)\n",
    "\n",
    "    # RC run\n",
    "    f, PSD_LS = bochamm.utils.compute_PS_PS(pds_l023_removed.frequency.values, pds_l023_removed.power.values, \n",
    "                                            300, \n",
    "                                            0.3, freqs,\n",
    "                                            lower_tau_lim=120, upper_tau_lim=400)   \n",
    "    rc_dpi1_guess = (1/f)[np.argmax(PSD_LS)]\n",
    "    rc_dpi1_max = np.max(PSD_LS)\n",
    "    \n",
    "    if rgb_dpi1_max > rc_dpi1_max:\n",
    "        if abs(rgb_dpi1_guess - (bochamm.utils.DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu)/2))/(bochamm.utils.DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu)/2) < 0.1:\n",
    "            #print(\"Best guess from PSxPS could be a harmonic, doubling.\")\n",
    "            rgb_dpi1_guess *= 2\n",
    "            harmonic = \"first\"\n",
    "        elif abs(rgb_dpi1_guess - (bochamm.utils.DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu)/3))/(bochamm.utils.DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu)/3) < 0.1:\n",
    "            #print(\"Best guess from PSxPS could be a harmonic, doubling.\")\n",
    "            rgb_dpi1_guess *= 3\n",
    "            harmonic = \"second\"\n",
    "        else:\n",
    "            harmonic = None\n",
    "        #print(\"Star is likely RGB\")\n",
    "\n",
    "        return rgb_dpi1_guess, rgb_dpi1_max, \"RGB\", harmonic\n",
    "    else:\n",
    "        #print(\"Star is likely RC\")\n",
    "        return rc_dpi1_guess, rc_dpi1_max, \"RC\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_threshold_results(X, fX, threshold, save=None):\n",
    "    # Set up for clustering\n",
    "    X_clust = X[-fX > threshold, :] \n",
    "    fX_clust = fX[-fX > threshold]\n",
    "    \n",
    "    # Hyperparameters still need to be robustly decided, but these aren't too bad\n",
    "    #clust = OPTICS(min_samples=100, max_eps=1, xi=0.05, min_cluster_size=0.05)\n",
    "    clust = OPTICS(min_samples=30, xi=0.5)#, min_cluster_size=0.05)\n",
    "\n",
    "    # Run the fit\n",
    "    clust.fit(X_clust)\n",
    "\n",
    "    labels_050 = cluster_optics_dbscan(\n",
    "        reachability=clust.reachability_,\n",
    "        core_distances=clust.core_distances_,\n",
    "        ordering=clust.ordering_,\n",
    "        eps=0.5,\n",
    "    )\n",
    "    labels_200 = cluster_optics_dbscan(\n",
    "        reachability=clust.reachability_,\n",
    "        core_distances=clust.core_distances_,\n",
    "        ordering=clust.ordering_,\n",
    "        eps=2,\n",
    "    )\n",
    "\n",
    "    space = np.arange(len(X_clust))\n",
    "    reachability = clust.reachability_[clust.ordering_]\n",
    "    labels = clust.labels_[clust.ordering_]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    G = gridspec.GridSpec(2, 3)\n",
    "    ax1 = plt.subplot(G[0, :])\n",
    "    ax2 = plt.subplot(G[1, 0])\n",
    "    ax3 = plt.subplot(G[1, 1])\n",
    "    ax4 = plt.subplot(G[1, 2])\n",
    "\n",
    "    # Reachability plot\n",
    "    colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\"]\n",
    "    for klass, color in zip(range(0, labels.max()+1), colors):\n",
    "        Xk = space[labels == klass]\n",
    "        Rk = reachability[labels == klass]\n",
    "        ax1.plot(Xk, Rk, color, alpha=0.3)\n",
    "    ax1.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.3)\n",
    "    ax1.plot(space, np.full_like(space, 2.0, dtype=float), \"k-\", alpha=0.5)\n",
    "    ax1.plot(space, np.full_like(space, 0.5, dtype=float), \"k-.\", alpha=0.5)\n",
    "    ax1.set_ylabel(\"Reachability (epsilon distance)\")\n",
    "    ax1.set_title(\"Reachability Plot\")\n",
    "\n",
    "    # OPTICS\n",
    "    colors = [f\"C{i}\" for i in range(10)]\n",
    "    #colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\", \"C0\", \"C1\"]\n",
    "    for klass, color in zip(range(0, labels.max()+1), colors):\n",
    "        Xk = X_clust[clust.labels_ == klass]\n",
    "        ax2.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)\n",
    "    ax2.plot(X_clust[clust.labels_ == -1, 0], X_clust[clust.labels_ == -1, 1], \"k+\", alpha=0.1)\n",
    "    ax2.set_title(\"Automatic Clustering\\nOPTICS\")\n",
    "\n",
    "    # DBSCAN at 0.5\n",
    "    #colors = [\"g\", \"greenyellow\", \"olive\", \"r\", \"b\", \"c\"]\n",
    "    for klass, color in zip(range(0, labels_050.max()+1), colors):\n",
    "        Xk = X_clust[labels_050 == klass]\n",
    "        ax3.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3, marker=\".\")\n",
    "    ax3.plot(X_clust[labels_050 == -1, 0], X_clust[labels_050 == -1, 1], \"k+\", alpha=0.1)\n",
    "    ax3.set_title(\"Clustering at 0.5 epsilon cut\\nDBSCAN\")\n",
    "\n",
    "    # DBSCAN at 2.\n",
    "    #colors = [\"g.\", \"m.\", \"y.\", \"c.\"]\n",
    "    for klass, color in zip(range(0, labels_200.max()+1), colors):\n",
    "        Xk = X_clust[labels_200 == klass]\n",
    "        ax4.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)\n",
    "    ax4.plot(X_clust[labels_200 == -1, 0], X_clust[labels_200 == -1, 1], \"k+\", alpha=0.1)\n",
    "    ax4.set_title(\"Clustering at 2.0 epsilon cut\\nDBSCAN\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save is not None:\n",
    "        plt.savefig(save, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return X_clust[clust.labels_ >= 0, :], fX_clust[clust.labels_ >= 0], clust.labels_[clust.labels_ >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clusters(data, loss, labels):\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    med_loss = np.zeros(n_clusters)\n",
    "    percentiles_DPi1 = np.zeros([n_clusters, 5])\n",
    "    percentiles_q = np.zeros([n_clusters, 5])\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        med_loss[i] = np.median(loss[labels == i])\n",
    "        percentiles_DPi1[i,:] = np.percentile(data[labels == i, 0], q=[2.5, 16, 50, 84, 97.5])\n",
    "        percentiles_q[i,:] = np.percentile(data[labels == i, 1], q=[2.5, 16, 50, 84, 97.5])\n",
    "\n",
    "    return med_loss, percentiles_DPi1, percentiles_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_opt(kic, save=False, verbose=True):\n",
    "    print(kic)\n",
    "    summary, pds, peaks, pds_l023_removed = prep_data(kic)\n",
    "    \n",
    "    # Create artificial frequencies for creation of stretched power spectrum using values determined from TACO for this star\n",
    "    freqs = frequencies.Frequencies(frequency=pds_l023_removed.frequency.values,\n",
    "                                    numax=summary.numax.values, \n",
    "                                    delta_nu=summary.DeltaNu.values if np.isfinite(summary.DeltaNu.values) else None, \n",
    "                                    epsilon_p=summary.eps_p.values if np.isfinite(summary.eps_p.values) else None,\n",
    "                                    alpha=summary.alpha.values if np.isfinite(summary.alpha.values) else None)\n",
    "    \n",
    "    dpi1_guess, dpi1_guess_power, evo_state_guess, harmonic = initial_RGB_or_RC(pds_l023_removed, freqs)\n",
    "\n",
    "    optim = bochamm.optimise.PSxPSOptimisation(pds_l023_removed, freqs)\n",
    "    X, fX, turbo1 = optim.run_optimisation(init_dpi=dpi1_guess, harmonic=harmonic, verbose=verbose)\n",
    "    \n",
    "    fX = fX.ravel()\n",
    "    ind_best = np.argmin(fX)\n",
    "    f_best, x_best = fX[ind_best], X[ind_best, :]\n",
    "    \n",
    "    if save:\n",
    "        np.savetxt(f\"{kic}_samples.txt\", np.c_[X, fX])\n",
    "    \n",
    "    extraction_kwargs = dict(return_threshold = True, plot=False)\n",
    "    threshold_results = bochamm.extract_results.extract_results(X, fX, bayes_opt_method=turbo1, extraction_method=\"thresholding\", extraction_kwargs=extraction_kwargs)\n",
    "\n",
    "   \n",
    "    extraction_kwargs = dict(eps=None, min_samples=30, n_neighbours=3, verbose=True, plot=False)\n",
    "    results = bochamm.extract_results.extract_results(X, fX, bayes_opt_method=turbo1, extraction_method=\"clustering\", extraction_kwargs=extraction_kwargs)\n",
    "    colors = ['royalblue', 'maroon', 'forestgreen', 'mediumorchid', 'tan', 'deeppink', 'olive', 'goldenrod', 'lightcyan', 'navy']\n",
    "    vectorizer = np.vectorize(lambda x: colors[x % len(colors)])\n",
    "   \n",
    "    threshold = threshold_results.threshold\n",
    "    n_clusters = len(np.unique(results.reduced_cluster_labels))\n",
    "    \n",
    "    cond = (-fX > threshold_results.threshold) \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(20, 24))\n",
    "    ax[0].scatter(X[:,0], X[:,1], c=fX)\n",
    "    ax[0].set_xlabel(r'$\\Delta\\Pi_{1}$ (s)', fontsize=18)\n",
    "    ax[0].set_ylabel(r'q', fontsize=18)\n",
    "    ax[1].scatter(X[cond,0], X[cond,1], c=fX[cond])\n",
    "    ax[1].set_xlabel(r'$\\Delta\\Pi_{1}$ (s)', fontsize=18)\n",
    "    ax[1].set_ylabel(r'q', fontsize=18)\n",
    "    ax[2].scatter(results.reduced_data[:,0], results.reduced_data[:,1], c=vectorizer(results.reduced_cluster_labels))\n",
    "    ax[2].set_xlabel(r'$\\Delta\\Pi_{1}$ (s)', fontsize=18)\n",
    "    ax[2].set_ylabel(r'q', fontsize=18)\n",
    "    if save:\n",
    "        plt.savefig(f\"{kic}_clustering_thresholding_comparison.png\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    cluster_X, cluster_loss, cluster_thresh_labels = cluster_threshold_results(X, fX, threshold, save=f\"{kic}_cluster_thresholds.png\")#\n",
    "    n_threshold_clusters = len(np.unique(cluster_thresh_labels))\n",
    "    \n",
    "    # Iterate over solutions and get uncertainties\n",
    "    # Firstly from clustering\n",
    "    cluster_med_loss, cluster_DPi1_perc, cluster_q_perc = process_clusters(results.reduced_data, results.reduced_loss, results.reduced_cluster_labels)\n",
    "    #print(\"Clustering results\")\n",
    "    # Secondly from clustering of thresholding\n",
    "    thresh_med_loss, thresh_DPi1_perc, thresh_q_perc = process_clusters(cluster_X, cluster_loss, cluster_thresh_labels)\n",
    "    #print(\"Thresholding results\")\n",
    "    if save:\n",
    "        np.savetxt(f\"{kic}_best.txt\", np.r_[x_best, np.array([dpi1_guess, dpi1_guess_power])])\n",
    "        np.savetxt(f\"{kic}_cluster_results.txt\", np.c_[np.r_[cluster_DPi1_perc, cluster_q_perc], np.tile(np.array([cluster_med_loss]), (np.shape(cluster_DPi1_perc)[0]*2, 1))])\n",
    "        np.savetxt(f\"{kic}_threshold_results.txt\", np.c_[np.r_[thresh_DPi1_perc, thresh_q_perc], np.tile(np.array([thresh_med_loss]), (np.shape(thresh_DPi1_perc)[0]*2, 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "To start with we're going to use a fast rotating star KIC 8564976 (a.k.a KOI-3890). This may seem counter intuitive since going for a complicated case straight away does not seem wise, but all will become clear a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "kics = glob.glob('../../TACO_benchmarking/data/intermediate/*/summary.csv')\n",
    "kics = [int(i.split('/')[-2]) for i in kics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kics = [1569842, 1726291, 2998532, 3129312, 3222834, 3426673, 3432802,\n",
    "       #3641504, 7619745]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=4)(delayed(run_opt)(kics[i], save=True, verbose=False) for i in tqdm(range(len(kics)), total=len(kics)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
