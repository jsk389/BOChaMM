{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d7f132",
   "metadata": {},
   "source": [
    "# Optimizing the Stretched Period Echelle using Peakbagged Modes\n",
    "## This is Step 2 in our method of characterizing the mixed modes of low-luminosity giants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b935c",
   "metadata": {},
   "source": [
    "### Loading dependencies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46703cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import time as timer\n",
    "import sloscillations.frequencies\n",
    "\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import qmc\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "from sklearn.neighbors import KDTree\n",
    "from turbo.turbo import Turbo1, TurboM\n",
    "from turbo.turbo.utils import from_unit_cube, latin_hypercube, to_unit_cube\n",
    "from scipy.spatial.distance import cdist\n",
    "from sloscillations import mixed_modes_utils, frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012da454",
   "metadata": {},
   "source": [
    "### Loading in helper functions needed to process the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e89b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' It is assumed that DeltaNu is in Î¼Hz\n",
    "def DeltaPi1_from_DeltaNu_RGB(DeltaNu):\n",
    "    # Compute Period spacing (in s) from deltanu\n",
    "    return 60 + 1.7*DeltaNu\n",
    "\n",
    "def Lor_model(pds, peak):\n",
    "    return peak.height / (1 + ((pds.frequency.values - peak.frequency)/peak.linewidth)**2)\n",
    "\n",
    "def sinc2_model(pds, peak):\n",
    "    deltanu = np.mean(np.diff(pds.frequency.values))\n",
    "    return peak.height * np.sinc((pds.frequency.values - peak.frequency)/deltanu)**2\n",
    "\n",
    "def fit_model(pds, peaks):\n",
    "\n",
    "    model = np.ones_like(pds.frequency.values)\n",
    "\n",
    "    for i in range(len(peaks)):\n",
    "        if np.isfinite(peaks.linewidth.iloc[i]):\n",
    "            model += Lor_model(pds, peaks.iloc[i,])\n",
    "        else:\n",
    "            model += sinc2_model(pds, peaks.iloc[i, ])\n",
    "    return model\n",
    "\n",
    "def prepare_l1_peaks(peaks: pd.DataFrame, summary: pd.DataFrame,\n",
    "                     AIC_cut: [float] = 0.0, height_cut: [float] = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract the mixed modes from the peaks dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    peaks: pd.DataFrame\n",
    "        Dataframe containing the detected peaks and parameters.\n",
    "        \n",
    "    summary: pd.DataFrame\n",
    "        Dataframe containing the global stellar information.\n",
    "    \n",
    "    AIC_cut: Optional[float] = 0.0\n",
    "        Cut to make in the Akaike Information Criterion if desired.\n",
    "        \n",
    "    height_cut: Optional[float] = 0.0\n",
    "        Cut to make in the mode height if desired.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Dataframe containing the mixed mode peaks and associated mode parameters.\n",
    "    \"\"\"\n",
    "    peaks['x'] = ((peaks['frequency'] % summary['DeltaNu'].values - summary['eps_p'].values) / summary['DeltaNu'].values) % 1\n",
    "    # Don't want to include any modes near l=0 or 2s, this is why this and the step in the next cell is performed.\n",
    "    x_range = [(np.minimum(np.min(peaks.loc[peaks['l'] == 0, 'x']), np.min(peaks.loc[peaks['l'] == 2, 'x'])) - 0.05) % 1,\n",
    "               (np.maximum(np.max(peaks.loc[peaks['l'] == 0, 'x']), np.max(peaks.loc[peaks['l'] == 2, 'x'])) + 0.05) % 1]\n",
    "    \n",
    "    l1_peaks = peaks.loc[(peaks.l == 1) | ~np.isfinite(peaks.l) | (peaks.l == 3)]\n",
    "    l1_peaks['x'] = ((l1_peaks['frequency'] % summary['DeltaNu'].values - summary['eps_p'].values) / summary['DeltaNu'].values) % 1\n",
    "    if x_range[0] < x_range[1]:\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] < x_range[1]) | (l1_peaks['x'] > x_range[0]), ] # changed to OR for HeB\n",
    "    else:\n",
    "        print(x_range)\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] > x_range[1]) & (l1_peaks['x'] < x_range[0]), ]\n",
    "\n",
    "\n",
    "    l1_peaks = l1_peaks.loc[(l1_peaks['height'] > height_cut), ]\n",
    "    l1_peaks = l1_peaks.loc[(l1_peaks['AIC'] > AIC_cut), ]\n",
    "\n",
    "    return l1_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02506dda",
   "metadata": {},
   "source": [
    "### Loading in data. Feel free to modify the KICID variable to any other star included in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a0b475",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9861900778160002, 0.029366167958541745]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-ec4d195fd1d7>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  l1_peaks['x'] = ((l1_peaks['frequency'] % summary['DeltaNu'].values - summary['eps_p'].values) / summary['DeltaNu'].values) % 1\n"
     ]
    }
   ],
   "source": [
    "kicx = 3973247\n",
    "\n",
    "data_folder = os.getcwd() + '/peakbag/intermediate/00%d/' %kicx\n",
    "\n",
    "summary = pd.read_csv(data_folder + 'summary.csv')\n",
    "pds = pd.read_csv(data_folder + 'pds_bgr.csv')\n",
    "peaks = pd.read_csv(data_folder + 'peaksMLE.csv')\n",
    "\n",
    "# Only keep pds around oscillations\n",
    "pds = pds.loc[abs(pds['frequency'].values - summary['numax'].values) < 3 * summary['sigmaEnv'].values, ]\n",
    "\n",
    "# Read in and filter peaks file to be within +/-3 sigmaEnv of numax\n",
    "peaks = peaks.loc[abs(peaks.frequency.values - summary.numax.values) < 3*summary.sigmaEnv.values, ]\n",
    "prepped_l1_peaks = prepare_l1_peaks(peaks, summary=summary, AIC_cut=10)\n",
    "\n",
    "# Optional: weighting the importance of each peak by their relative amplitude. \n",
    "# Here we try to weight the low-amplitude mixed modes more.\n",
    "prepped_l1_peaks['weights'] = (prepped_l1_peaks['amplitude']/np.sum(prepped_l1_peaks['amplitude']))*1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bae63d",
   "metadata": {},
   "source": [
    "### As in Step 1, we pass the peakbagged frequencies to the Frequencies class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2fe5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "l023_peaks = peaks.loc[(peaks.l == 0) | (peaks.l == 2) ]\n",
    "pds_l023_removed = pds.assign(power = pds.power / fit_model(pds, l023_peaks))\n",
    "\n",
    "freqs = frequencies.Frequencies(frequency=pds_l023_removed.frequency.values,\n",
    "                                numax=summary.numax.values, \n",
    "                                delta_nu=summary.DeltaNu.values if np.isfinite(summary.DeltaNu.values) else None, \n",
    "                                epsilon_p=summary.eps_p.values if np.isfinite(summary.eps_p.values) else None,\n",
    "                                alpha=summary.alpha.values if np.isfinite(summary.alpha.values) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b39527",
   "metadata": {},
   "source": [
    "### In this step, we are using the dipole ($l=1$) modes and trying to search for a combination of ($\\Delta\\Pi, q, \\epsilon_g, \\delta\\nu_{\\mathrm{rot}}$) that fits the mixed-mode pattern. \n",
    "\n",
    "### We will once again use TuRBO, but we will adopt the TuRBO-m algorithm that is more efficient in searching in higher-dimensional spaces.\n",
    "\n",
    "We have two separate objective functions depending or not we anticipate the presence of core rotational splitting. \n",
    "* `freq_tau_rot`: You can specify whether you choose to fit two ($m=-1, 1$) or three ($m=-1,0,1$) rotational components. If not known a priori, fitting for three is the recommended option to find a good fit.\n",
    "* `freq_tau_rot_singlet`: If you do not anticipate the presence of rotational splitting, use this function to fit only for $m=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5796f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class freq_tau_rot:\n",
    "    def __init__(self, inp_freqs, init_dpi, rot_lb=0.1, rot_ub=1.0, eps_g_lb = -0.5, eps_g_ub = 0.5,  nb_comp = 3,\n",
    "                weights=None):\n",
    "        self.lb = np.array([init_dpi*0.98, 0.05, eps_g_lb, rot_lb])\n",
    "        self.ub = np.array([init_dpi*1.02, 0.4, eps_g_ub, rot_ub]) \n",
    "        self.nb_comp = nb_comp\n",
    "        self.weights = weights\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == 4\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        \n",
    "        dpi1, coupling, eps_g, split = x[0], x[1], x[2], x[3]\n",
    "           \n",
    "        params = {'calc_l0': True, # copy of params with DPi1 set to candidate dpi from loop\n",
    "            'calc_l2': True, \n",
    "            'calc_l3': False, \n",
    "            'calc_nom_l1': True, \n",
    "            'calc_mixed': True, \n",
    "            'calc_rot': False,\n",
    "            'DPi1': dpi1,\n",
    "            'coupling': coupling, \n",
    "            'eps_g': eps_g, \n",
    "            'split_core': split,\n",
    "            'split_env': 0.0,\n",
    "            'l': 1,\n",
    "            }\n",
    "    \n",
    "        freqs(params)\n",
    "\n",
    "        freqs.generate_tau_values()\n",
    "\n",
    "        # Compute tau from the zeta value just computed\n",
    "        real_tau = mixed_modes_utils.peaks_stretched_period(inp_freqs, \n",
    "                                                                 freqs.frequency, \n",
    "                                                                 freqs.tau)\n",
    "\n",
    "        freqs_p1 = freqs.l1_mixed_freqs + freqs.l1_zeta * split\n",
    "        freqs_n1 = freqs.l1_mixed_freqs - freqs.l1_zeta * split\n",
    "\n",
    "        tau_p1 = mixed_modes_utils.peaks_stretched_period(\n",
    "            freqs_p1, freqs.frequency, freqs.tau)\n",
    "        tau_n1 = mixed_modes_utils.peaks_stretched_period(freqs_n1, freqs.frequency, freqs.tau)\n",
    "\n",
    "        model_freqs = np.c_[freqs.l1_mixed_freqs, freqs_p1, freqs_n1]\n",
    "        model_tau = np.c_[freqs.l1_mixed_tau, tau_p1, tau_n1]   \n",
    "\n",
    "\n",
    "        if self.nb_comp == 2:\n",
    "            X = np.c_[np.r_[model_tau[:,1] - freqs.shift * freqs.DPi1, \n",
    "                            model_tau[:,2] - freqs.shift * freqs.DPi1], \n",
    "                      np.r_[model_freqs[:,1], \n",
    "                            model_freqs[:,2]]]\n",
    "        else:\n",
    "            X = np.c_[np.r_[model_tau[:,0],\n",
    "                            model_tau[:,1] - freqs.shift * freqs.DPi1, \n",
    "                            model_tau[:,2] - freqs.shift * freqs.DPi1], \n",
    "                      np.r_[model_freqs[:,0],\n",
    "                            model_freqs[:,1], \n",
    "                            model_freqs[:,2]]]\n",
    "\n",
    "\n",
    "        y_real = (real_tau - freqs.DPi1*(freqs.shift))\n",
    "        X_real = np.c_[y_real, inp_freqs]\n",
    "        \n",
    "        # now compute distance between original frequencies with the frequencies under a new model hypothesis\n",
    "\n",
    "        c1 = np.vstack((X[:,0]/freqs.DPi1, (X[:,1]-freqs.numax)/freqs.delta_nu)).T\n",
    "        c2 = np.vstack((X_real[:,0]/freqs.DPi1, (X_real[:,1]-freqs.numax)/freqs.delta_nu)).T\n",
    "        tree = KDTree(c1, metric='euclidean')\n",
    "        nearest_dists, nearest_idx = tree.query(c2, k=1)\n",
    "        \n",
    "        if self.weights is not None:\n",
    "            return np.median(nearest_dists*self.weights)\n",
    "        else:\n",
    "            return np.median(nearest_dists)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class freq_tau_rot_singlet:\n",
    "    def __init__(self, inp_freqs, init_dpi, eps_g_lb = -0.5, eps_g_ub = 0.3, weights = None):\n",
    "        self.lb = np.array([init_dpi*0.98, 0.05, eps_g_lb])\n",
    "        self.ub = np.array([init_dpi*1.02, 0.4, eps_g_ub])\n",
    "        self.weights = weights\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert len(x) == 3\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        \n",
    "        dpi1, coupling, eps_g = x[0], x[1], x[2]\n",
    "         \n",
    "        params = {'calc_l0': True, # copy of params with DPi1 set to candidate dpi from loop\n",
    "            'calc_l2': True, \n",
    "            'calc_l3': False, \n",
    "            'calc_nom_l1': True, \n",
    "            'calc_mixed': True, \n",
    "            'calc_rot': False,\n",
    "            'DPi1': dpi1,\n",
    "            'coupling': coupling, \n",
    "            'eps_g': eps_g, \n",
    "            'split_core': 0.0,\n",
    "            'split_env': 0.0,\n",
    "            'l': 1,\n",
    "            }\n",
    "    \n",
    "        freqs(params)\n",
    "        freqs.generate_tau_values()\n",
    "\n",
    "        # Compute tau from the zeta value just computed\n",
    "        real_tau = mixed_modes_utils.peaks_stretched_period(inp_freqs, \n",
    "                                                                 freqs.frequency, \n",
    "                                                                 freqs.tau)\n",
    "\n",
    "\n",
    "        model_freqs = freqs.l1_mixed_freqs.reshape(-1,1)\n",
    "        model_tau = freqs.l1_mixed_tau.reshape(-1,1)\n",
    "\n",
    "        X = np.c_[model_tau[:,0], model_freqs[:,0]]    \n",
    "        y_real = (real_tau - freqs.DPi1*(freqs.shift))\n",
    "        X_real = np.c_[y_real, inp_freqs]\n",
    "\n",
    "        ## KDTree ##\n",
    "        c1 = np.vstack((X[:,0]/freqs.DPi1, (X[:,1]-freqs.numax)/freqs.delta_nu)).T\n",
    "        c2 = np.vstack((X_real[:,0]/freqs.DPi1, (X_real[:,1]-freqs.numax)/freqs.delta_nu)).T\n",
    "        tree = KDTree(c1, metric='euclidean')\n",
    "        nearest_dists, nearest_idx = tree.query(c2, k=1)\n",
    "        \n",
    "        if self.weights is not None:\n",
    "            return np.median(nearest_dists*self.weights)\n",
    "        else:\n",
    "            return np.median(nearest_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924422c8",
   "metadata": {},
   "source": [
    "### The inputs into the objective function concern the range over which to search:\n",
    "\n",
    "`inp_freqs`: The dipole mode frequencies that we wish to match to a model of the stretched period echelle diagram.\n",
    "\n",
    "`init_dpi`: The value of $\\Delta\\Pi$ over which we will search over. Searching over a more restricted but informed range of $\\Delta\\Pi$ greatly improves the likelihood of finding a good solution. Ideally, this will be set to the optimal $\\Delta\\Pi$ from the PSxPS from Part 1. For this demo, we will use the $\\Delta\\Pi$ inferred from $\\Delta\\nu$.\n",
    "\n",
    "`rot_lb`: $\\delta\\nu_{\\mathrm{rot}}$ lower bound. Default: 0.1\n",
    "\n",
    "`rot_ub`: $\\delta\\nu_{\\mathrm{rot}}$ upper bound. Default: 1.0\n",
    "\n",
    "`eps_g_lb`: $\\epsilon_g$ lower bound. Default: -0.5\n",
    "\n",
    "`eps_g_ub`: $\\epsilon_g$ upper bound. Default: 0.5\n",
    "\n",
    "`nb_comp`: Only pertinent to `freq_tau_rot`. Number of rotationally split components (2 or 3). Default: 3.\n",
    "\n",
    "`weights`: Weights for each mixed mode. Default: None (i.e. unweighted). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57214661",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rot = freq_tau_rot(inp_freqs = prepped_l1_peaks['frequency'].values,# generic case\n",
    "    init_dpi=DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu)[0],\n",
    "    rot_lb=0.05, \n",
    "    rot_ub=1.0,\n",
    "    eps_g_lb = -0.05, \n",
    "    eps_g_ub =0.35, \n",
    "    nb_comp = 3, \n",
    "    weights=(prepped_l1_peaks['amplitude'].values/np.sum(prepped_l1_peaks['amplitude'].values))*1000.) \n",
    "\n",
    "# f_rot = freq_tau_rot_singlet( # fitting only m=0\n",
    "#     init_dpi = DeltaPi1_from_DeltaNu_RGB(freqs.delta_nu), \n",
    "#     eps_g_lb = -0.5,\n",
    "#     eps_g_ub =0.35, \n",
    "#     weights=(prepped_l1_peaks['amplitude'].values/np.sum(prepped_l1_peaks['amplitude'].values))*1000.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29e7fe",
   "metadata": {},
   "source": [
    "### Now proceed with optimization using TuRBO-m. Since the space is now higher-dimensional compared to Step 1, we will now run over 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4f03136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dtype = torch.float64 \n",
      "Using device = cuda\n"
     ]
    }
   ],
   "source": [
    "# Turbo M\n",
    "turbo1_rot = TurboM(\n",
    "    f=f_rot,  # Handle to objective function\n",
    "    lb=f_rot.lb,  # Numpy array specifying lower bounds\n",
    "    ub=f_rot.ub,  # Numpy array specifying upper bounds\n",
    "    n_init=50,  # Number of initial bounds from an Symmetric Latin hypercube design\n",
    "    max_evals=5000,  # Maximum number of evaluations\n",
    "    n_trust_regions=10,  # Number of trust regions\n",
    "    batch_size=100,  # How large batch size TuRBO uses\n",
    "    verbose=True,  # Print information from each batch\n",
    "    use_ard=True,  # Set to true if you want to use ARD for the GP kernel\n",
    "    max_cholesky_size=2000,  # When we switch from Cholesky to Lanczos\n",
    "    n_training_steps=50,  # Number of steps of ADAM to learn the hypers\n",
    "    min_cuda=64,  # Run on the CPU for small datasets\n",
    "    device=\"cuda\",  # \"cpu\" or \"cuda\"\n",
    "    dtype=\"float64\",  # float64 or float32\n",
    ")\n",
    "# turbo1_rot.failtol = 20 # double the tolerance\n",
    "turbo1_rot.n_cand = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7f267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR-0 starting from: 0.7605\n",
      "TR-1 starting from: 0.6052\n",
      "TR-2 starting from: 0.8629\n",
      "TR-3 starting from: 0.7989\n",
      "TR-4 starting from: 0.847\n",
      "TR-5 starting from: 0.6471\n",
      "TR-6 starting from: 0.513\n",
      "TR-7 starting from: 0.8737\n",
      "TR-8 starting from: 0.7596\n",
      "TR-9 starting from: 0.801\n",
      "800) New best @ TR-7: 0.3655, Best Sol: [81.24439736  0.15669165  0.10937384  0.35654226]\n",
      "900) New best @ TR-7: 0.3487, Best Sol: [8.13320099e+01 1.61855645e-01 6.07940479e-02 4.22633054e-01]\n",
      "1000) New best @ TR-7: 0.2752, Best Sol: [8.13064422e+01 1.19359569e-01 6.60456711e-02 3.76863689e-01]\n",
      "1200) New best @ TR-7: 0.2139, Best Sol: [8.13375877e+01 1.42076700e-01 3.34233657e-02 4.06938969e-01]\n",
      "1500) New best @ TR-7: 0.1992, Best Sol: [8.13112996e+01 1.43893250e-01 5.92912630e-02 4.07717470e-01]\n",
      "1600) New best @ TR-7: 0.1835, Best Sol: [81.28850341  0.14216652  0.0816418   0.39237106]\n",
      "1900) New best @ TR-7: 0.1748, Best Sol: [81.27678653  0.14557301  0.09218362  0.40283804]\n",
      "2200) TR-7 converged to: : 0.1748\n"
     ]
    }
   ],
   "source": [
    "init_time = timer.time()\n",
    "turbo1_rot.optimize()\n",
    "print('Elapsed Time: ', timer.time()-init_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a7b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
