{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "import sobol_seq\n",
    "\n",
    "from astropy.timeseries import LombScargle\n",
    "import sys\n",
    "sys.path.append('../sloscillations/TuRBO/')\n",
    "from turbo import Turbo1, TurboM\n",
    "from turbo.utils import from_unit_cube, latin_hypercube, to_unit_cube\n",
    "import frequencies, mixed_modes_utils\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define save folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../results/images/'\n",
    "samples_folder = '../results/samples/'\n",
    "output_file = '../results/rotation_Mosser2016_ABBA.txt'\n",
    "abba_psd_folder = '../data/KeplerRGpeakbagging/Kallinger_Vrard_BGCorr/'\n",
    "abba_folder = '../data/KeplerRGpeakbagging/ModeFiles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.read_csv('../data/KeplerRGpeakbagging/summary.dat', delimiter=';').rename(columns={'ID': 'KIC'})\n",
    "mos_q_df = pd.read_csv('Mosser_2016.dat', delim_whitespace=True)\n",
    "mos_q_df = mos_q_df.rename(columns={'DPi1': 'dpi'})\n",
    "summary_df = summary_df.merge(mos_q_df, how='inner', on='KIC')\n",
    "summary_df = summary_df[summary_df.evo == 0] # For now pick only RGB\n",
    "\n",
    "## here summary_df is the intersection of RGB stars peakbagged by Kallinger that are in the Mosser 2016 paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble code for processing ABBA data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' It is assumed that DeltaNu is in Î¼Hz\n",
    "def DeltaPi1_from_DeltaNu_RGB(DeltaNu):\n",
    "    # Compute Period spacing (in s) from deltanu\n",
    "    return 60 + 1.7*DeltaNu\n",
    "\n",
    "def Lor_model(pds, peak):\n",
    "    return peak.height / (1 + ((pds.frequency.values - peak.freq)/ (peak.linewidth/2))**2) # add /2 factor to peak.linewidth\n",
    "\n",
    "def sinc2_model(pds, peak):\n",
    "    deltanu = np.mean(np.diff(pds.frequency.values))\n",
    "    return peak.height * np.sinc((pds.frequency.values - peak.freq)/deltanu)**2\n",
    "\n",
    "def fit_model(pds, peaks):\n",
    "\n",
    "    model = np.ones_like(pds.frequency.values) # times 2?\n",
    "\n",
    "    for i in range(len(peaks)):\n",
    "        if np.isfinite(peaks.linewidth.iloc[i]):\n",
    "            model += Lor_model(pds, peaks.iloc[i,])\n",
    "        else:\n",
    "            model += sinc2_model(pds, peaks.iloc[i, ])\n",
    "    return model\n",
    "\n",
    "def prepare_l1_peaks(peaks: pd.DataFrame,\n",
    "                     evidence_cut: [float] = 0.0, height_cut: [float] = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract the mixed modes from the peaks dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    peaks: pd.DataFrame\n",
    "        Dataframe containing the detected peaks and parameters.\n",
    "        \n",
    "    summary: pd.DataFrame\n",
    "        Dataframe containing the global stellar information.\n",
    "    \n",
    "    AIC_cut: Optional[float] = 0.0\n",
    "        Cut to make in the Akaike Information Criterion if desired.\n",
    "        \n",
    "    height_cut: Optional[float] = 0.0\n",
    "        Cut to make in the mode height if desired.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Dataframe containing the mixed mode peaks and associated mode parameters.\n",
    "    \"\"\"\n",
    "    peaks['x'] = ((peaks['freq'] % dnu - eps) / dnu) % 1\n",
    "    # Don't want to include any modes near l=0 or 2s, this is why this and the step in the next cell is performed.\n",
    "    x_range = [(np.minimum(np.min(peaks.loc[peaks['l'] == 0, 'x']), np.min(peaks.loc[peaks['l'] == 2, 'x'])) - 0.05) % 1,\n",
    "               (np.maximum(np.max(peaks.loc[peaks['l'] == 0, 'x']), np.max(peaks.loc[peaks['l'] == 2, 'x'])) + 0.05) % 1]\n",
    "    \n",
    "    l1_peaks = peaks.loc[(peaks.l == 1) | ~np.isfinite(peaks.l), ]\n",
    "    l1_peaks['x'] = ((l1_peaks['freq'] % dnu - eps) / dnu) % 1\n",
    "    \n",
    "    if x_range[0] < x_range[1]:\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] < x_range[1]) | (l1_peaks['x'] > x_range[0]), ] # changed to OR for HeB\n",
    "    else:\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] > x_range[1]) & (l1_peaks['x'] < x_range[0]), ] # this is AND for RGB\n",
    "#     print(l1_peaks)\n",
    "    l1_peaks = l1_peaks.loc[(l1_peaks['height'] > height_cut), ]\n",
    "    l1_peaks = l1_peaks.loc[(l1_peaks['ev1'] > evidence_cut), ]\n",
    "\n",
    "    return l1_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "def kdtree_match(X_model, X_real, DPi1, numax, delta_nu, weights):\n",
    "    c1 = np.vstack((X_model[:,0]/DPi1, (X_model[:,1]-numax)/delta_nu)).T\n",
    "    c2 = np.vstack((X_real[:,0]/DPi1, (X_real[:,1]-numax)/delta_nu)).T\n",
    "\n",
    "    kdtree = KDTree(c1)\n",
    "    distances, idx = kdtree.query(c2, k=1)\n",
    "    dist = np.median(distances*weights)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class freq_tau_rot_triplet:\n",
    "    def __init__(self, init_dpi, init_q, freqs_class, inp_freqs, weights):\n",
    "        self.lb = np.array([init_dpi*0.98, max(0, init_q-0.1), -0.4, 0.1]) #or another judicious choice\n",
    "        self.ub = np.array([init_dpi*1.02, init_q+0.1, 0.4, 1.0]) ## RGB\n",
    "        \n",
    "#         self.lb = np.array([init_dpi*0.98, 0.05, -0.5, 0.0]) \n",
    "#         self.ub = np.array([init_dpi*1.02, 0.6, 0.2, 0.1]) # HeB\n",
    "        self.freqs = freqs_class\n",
    "        self.inp_freqs = inp_freqs\n",
    "        self.weights = weights\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == 4\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        \n",
    "        dpi1, coupling, eps_g, split = x[0], x[1], x[2], x[3]\n",
    "        \n",
    "        params = {'calc_l0': True, # copy of params with DPi1 set to candidate dpi from loop\n",
    "            'calc_l2': True, \n",
    "            'calc_l3': False, \n",
    "            'calc_nom_l1': True, \n",
    "            'calc_mixed': True, \n",
    "            'calc_rot': False,\n",
    "            'DPi1': dpi1,\n",
    "            'coupling': coupling, \n",
    "            'eps_g': eps_g, \n",
    "            'split_core': split,\n",
    "            'split_env': 0.0,\n",
    "            'l': 1,\n",
    "            }\n",
    "    \n",
    "        self.freqs(params)\n",
    "\n",
    "        self.freqs.generate_tau_values()\n",
    "\n",
    "        # Compute tau from the zeta value just computed\n",
    "        real_tau = mixed_modes_utils.peaks_stretched_period(self.inp_freqs, \n",
    "                                                                 self.freqs.frequency, \n",
    "                                                                 self.freqs.tau)\n",
    "\n",
    "        freqs_p1 = self.freqs.l1_mixed_freqs + self.freqs.l1_zeta * split\n",
    "        freqs_n1 = self.freqs.l1_mixed_freqs - self.freqs.l1_zeta * split\n",
    "\n",
    "        tau_p1 = mixed_modes_utils.peaks_stretched_period(freqs_p1, self.freqs.frequency, self.freqs.tau)\n",
    "        tau_n1 = mixed_modes_utils.peaks_stretched_period(freqs_n1, self.freqs.frequency, self.freqs.tau)\n",
    "\n",
    "        model_freqs = np.c_[self.freqs.l1_mixed_freqs, freqs_p1, freqs_n1]\n",
    "        model_tau = np.c_[self.freqs.l1_mixed_tau, tau_p1, tau_n1]   \n",
    "\n",
    "#         # #triplet case\n",
    "        X = np.c_[np.r_[model_tau[:,0],\n",
    "                        model_tau[:,1] - self.freqs.shift * self.freqs.DPi1, \n",
    "                        model_tau[:,2] - self.freqs.shift * self.freqs.DPi1], \n",
    "                  np.r_[model_freqs[:,0],\n",
    "                        model_freqs[:,1], \n",
    "                        model_freqs[:,2]]]\n",
    "\n",
    "\n",
    "        y_real = (real_tau - self.freqs.DPi1*(self.freqs.shift))\n",
    "        X_real = np.c_[y_real, self.inp_freqs]\n",
    "\n",
    "        # now compute distance between original frequencies with the frequencies under a new model hypothesis\n",
    "\n",
    "        dist = 0\n",
    "        \n",
    "        dist += kdtree_match(X_model=X, X_real=X_real,\n",
    "                                       DPi1=self.freqs.DPi1, numax=self.freqs.numax,\n",
    "                                       delta_nu=self.freqs.delta_nu, \n",
    "                                       weights=self.weights)\n",
    "\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "class freq_tau_rot_doublet:\n",
    "    def __init__(self, init_dpi, init_q, freqs_class, inp_freqs, weights):\n",
    "        self.lb = np.array([init_dpi*0.98, max(0, init_q-0.1), -0.4, 0.1]) #or another judicious choice\n",
    "        self.ub = np.array([init_dpi*1.02, init_q+0.1, 0.4, 1.0]) ## RGB\n",
    "        \n",
    "#         self.lb = np.array([init_dpi*0.98, 0.05, -0.5, 0.0]) \n",
    "#         self.ub = np.array([init_dpi*1.02, 0.6, 0.2, 0.1]) # HeB\n",
    "        self.freqs = freqs_class\n",
    "        self.inp_freqs = inp_freqs\n",
    "        self.weights = weights\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == 4\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        \n",
    "        dpi1, coupling, eps_g, split = x[0], x[1], x[2], x[3]\n",
    "        \n",
    "        params = {'calc_l0': True, # copy of params with DPi1 set to candidate dpi from loop\n",
    "            'calc_l2': True, \n",
    "            'calc_l3': False, \n",
    "            'calc_nom_l1': True, \n",
    "            'calc_mixed': True, \n",
    "            'calc_rot': False,\n",
    "            'DPi1': dpi1,\n",
    "            'coupling': coupling, \n",
    "            'eps_g': eps_g, \n",
    "            'split_core': split,\n",
    "            'split_env': 0.0,\n",
    "            'l': 1,\n",
    "            }\n",
    "    \n",
    "        self.freqs(params)\n",
    "\n",
    "        self.freqs.generate_tau_values()\n",
    "\n",
    "        # Compute tau from the zeta value just computed\n",
    "        real_tau = mixed_modes_utils.peaks_stretched_period(self.inp_freqs, \n",
    "                                                                 self.freqs.frequency, \n",
    "                                                                 self.freqs.tau)\n",
    "\n",
    "        freqs_p1 = self.freqs.l1_mixed_freqs + self.freqs.l1_zeta * split\n",
    "        freqs_n1 = self.freqs.l1_mixed_freqs - self.freqs.l1_zeta * split\n",
    "\n",
    "        tau_p1 = mixed_modes_utils.peaks_stretched_period(freqs_p1, self.freqs.frequency, self.freqs.tau)\n",
    "        tau_n1 = mixed_modes_utils.peaks_stretched_period(freqs_n1, self.freqs.frequency, self.freqs.tau)\n",
    "\n",
    "        model_freqs = np.c_[self.freqs.l1_mixed_freqs, freqs_p1, freqs_n1]\n",
    "        model_tau = np.c_[self.freqs.l1_mixed_tau, tau_p1, tau_n1]   \n",
    "\n",
    "#         # #doublet case\n",
    "        X = np.c_[np.r_[model_tau[:,1] - self.freqs.shift * self.freqs.DPi1, \n",
    "                        model_tau[:,2] - self.freqs.shift * self.freqs.DPi1], \n",
    "                  np.r_[model_freqs[:,1], \n",
    "                        model_freqs[:,2]]]\n",
    "\n",
    "\n",
    "        y_real = (real_tau - self.freqs.DPi1*(self.freqs.shift))\n",
    "        X_real = np.c_[y_real, self.inp_freqs]\n",
    "\n",
    "        # now compute distance between original frequencies with the frequencies under a new model hypothesis\n",
    "\n",
    "        dist = 0\n",
    "        \n",
    "        dist += kdtree_match(X_model=X, X_real=X_real,\n",
    "                                       DPi1=self.freqs.DPi1, numax=self.freqs.numax,\n",
    "                                       delta_nu=self.freqs.delta_nu, \n",
    "                                       weights=self.weights)\n",
    "\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "class freq_tau_rot_singlet:\n",
    "    def __init__(self, init_dpi, init_q, freqs_class, inp_freqs, weights):\n",
    "        self.lb = np.array([init_dpi*0.95, max(0, init_q-0.1), -0.5])\n",
    "        self.ub = np.array([init_dpi*1.05, init_q+0.1, 0.5])\n",
    "        self.freqs = freqs_class\n",
    "        self.inp_freqs = inp_freqs\n",
    "        self.weights = weights\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert len(x) == 3\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        \n",
    "        dpi1, coupling, eps_g = x[0], x[1], x[2]\n",
    "        \n",
    "        \n",
    "        params = {'calc_l0': True, # copy of params with DPi1 set to candidate dpi from loop\n",
    "            'calc_l2': True, \n",
    "            'calc_l3': False, \n",
    "            'calc_nom_l1': True, \n",
    "            'calc_mixed': True, \n",
    "            'calc_rot': False,\n",
    "            'DPi1': dpi1,\n",
    "            'coupling': coupling, \n",
    "            'eps_g': eps_g, \n",
    "            'split_core': 0.0,\n",
    "            'split_env': 0.0,\n",
    "            'l': 1,\n",
    "            }\n",
    "    \n",
    "        self.freqs(params)\n",
    "\n",
    "        self.freqs.generate_tau_values()\n",
    "\n",
    "        # Compute tau from the zeta value just computed\n",
    "        real_tau = mixed_modes_utils.peaks_stretched_period(self.inp_freqs, \n",
    "                                                                 self.freqs.frequency, \n",
    "                                                                 self.freqs.tau)\n",
    "\n",
    "\n",
    "        model_freqs = self.freqs.l1_mixed_freqs.reshape(-1,1)\n",
    "        model_tau = self.freqs.l1_mixed_tau.reshape(-1,1)\n",
    "\n",
    "        # singlet case  \n",
    "        X = np.c_[model_tau[:,0], model_freqs[:,0]]    \n",
    "        y_real = (real_tau - self.freqs.DPi1*(self.freqs.shift))\n",
    "        X_real = np.c_[y_real, self.inp_freqs]\n",
    "\n",
    "\n",
    "        y_real = (real_tau - self.freqs.DPi1*(self.freqs.shift))\n",
    "        X_real = np.c_[y_real, self.inp_freqs]\n",
    "\n",
    "        # now compute distance between original frequencies with the frequencies under a new model hypothesis\n",
    "\n",
    "        dist = 0\n",
    "\n",
    "\n",
    "        dist += kdtree_match(X_model=X, X_real=X_real,\n",
    "                                       DPi1=self.freqs.DPi1, numax=self.freqs.numax,\n",
    "                                       delta_nu=self.freqs.delta_nu, \n",
    "                                       weights=self.weights)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rotation(init_dpi, init_q, freqs_class, inp_freqs, loss_list_index, weights, verbose=True):\n",
    "    num_components = loss_list_index + 1\n",
    "    print('Number of Components: ', num_components)\n",
    "    \n",
    "    if num_components == 1:\n",
    "        z = freq_tau_rot_singlet(init_dpi, init_q, freqs_class, inp_freqs, weights)\n",
    "    elif num_components == 2:\n",
    "        z = freq_tau_rot_doublet(init_dpi, init_q, freqs_class, inp_freqs, weights)\n",
    "    elif num_components == 3:\n",
    "        z = freq_tau_rot_triplet(init_dpi, init_q, freqs_class, inp_freqs, weights)\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    turbo1_rot = TurboM(\n",
    "    f=z,  # Handle to objective function\n",
    "    lb=z.lb,  # Numpy array specifying lower bounds\n",
    "    ub=z.ub,  # Numpy array specifying upper bounds\n",
    "    n_init=50,  # Number of initial bounds from an Symmetric Latin hypercube design\n",
    "    max_evals=5000,  # Maximum number of evaluations\n",
    "    n_trust_regions=10,  # Number of trust regions\n",
    "    batch_size=100,  # How large batch size TuRBO uses\n",
    "    verbose=verbose,  # Print information from each batch\n",
    "    use_ard=True,  # Set to true if you want to use ARD for the GP kernel\n",
    "    max_cholesky_size=2000,  # When we switch from Cholesky to Lanczos\n",
    "    n_training_steps=50,  # Number of steps of ADAM to learn the hypers\n",
    "    min_cuda=64,  # Run on the CPU for small datasets\n",
    "    device=\"cuda\",  # \"cpu\" or \"cuda\"\n",
    "    dtype=\"float64\",  # float64 or float32\n",
    "    )\n",
    "\n",
    "\n",
    "#     turbo1_rot.failtol = 20 # double the tolerance\n",
    "    turbo1_rot.n_cand = 5000\n",
    "    turbo1_rot.optimize()\n",
    "    X_rot = turbo1_rot.X  # Evaluated points\n",
    "    fX_rot = turbo1_rot.fX  # Observed values\n",
    "    ind_best_rot = np.argmin(fX_rot)\n",
    "    f_best_rot, x_best_rot = fX_rot[ind_best_rot], X_rot[ind_best_rot, :]\n",
    "    return x_best_rot, f_best_rot, X_rot, fX_rot.ravel()\n",
    "\n",
    "\n",
    "def plot_solution(freqs_class, inp_freqs, prepped_l1_peaks, cand_dpi, cand_q, cand_eps_g, cand_rot, rot_index, axa, axb,\n",
    "                 label='BOpt', idx=0):\n",
    "    # Set up frequencies class\n",
    "    freqs_dummy = deepcopy(freqs_class)\n",
    "    splitting=cand_rot\n",
    "    \n",
    "    params = {'calc_l0': True, \n",
    "                'calc_l2': True, \n",
    "                'calc_l3': False, \n",
    "                'calc_nom_l1': True, \n",
    "                'calc_mixed': True, \n",
    "                'calc_rot': False, \n",
    "                'DPi1': cand_dpi,\n",
    "                'coupling': cand_q,\n",
    "                'eps_g': cand_eps_g,\n",
    "                'l': 1, \n",
    "                }\n",
    "\n",
    "    freqs_dummy(params)\n",
    "    freqs_dummy.generate_tau_values()\n",
    "    cand_dpi = freqs_dummy.DPi1\n",
    "\n",
    "    real_tau = mixed_modes_utils.peaks_stretched_period(inp_freqs, \n",
    "                                                             freqs_dummy.frequency, \n",
    "                                                             freqs_dummy.tau)\n",
    "    real_tau = real_tau - freqs_dummy.DPi1*(freqs_dummy.shift)\n",
    "\n",
    "\n",
    "    freqs_p1 = freqs_dummy.l1_mixed_freqs + freqs_dummy.l1_zeta * splitting\n",
    "    freqs_n1 = freqs_dummy.l1_mixed_freqs - freqs_dummy.l1_zeta * splitting\n",
    "\n",
    "    tau_p1 = mixed_modes_utils.peaks_stretched_period(freqs_p1, freqs_dummy.frequency, freqs_dummy.tau)\n",
    "    tau_n1 = mixed_modes_utils.peaks_stretched_period(freqs_n1, freqs_dummy.frequency, freqs_dummy.tau)\n",
    "\n",
    "    model_freqs = np.c_[freqs_dummy.l1_mixed_freqs, freqs_p1, freqs_n1]\n",
    "    model_tau = np.c_[freqs_dummy.l1_mixed_tau, tau_p1, tau_n1]\n",
    "\n",
    "    plot_tau = np.mod(real_tau, freqs_dummy.DPi1)\n",
    "    plot_tau[plot_tau > freqs_dummy.DPi1/2] -= freqs_dummy.DPi1\n",
    "    \n",
    "    if rot_index == 0:\n",
    "        X = np.c_[model_tau[:,0], model_freqs[:,0]]\n",
    "    elif rot_index == 1:\n",
    "        X = np.c_[np.r_[model_tau[:,1] - freqs_dummy.shift * freqs_dummy.DPi1, \n",
    "                        model_tau[:,2] - freqs_dummy.shift * freqs_dummy.DPi1], \n",
    "                  np.r_[model_freqs[:,1], \n",
    "                        model_freqs[:,2]]] \n",
    "    elif rot_index == 2:  \n",
    "        X = np.c_[np.r_[model_tau[:,0],\n",
    "                        model_tau[:,1] - freqs_dummy.shift * freqs_dummy.DPi1, \n",
    "                        model_tau[:,2] - freqs_dummy.shift * freqs_dummy.DPi1], \n",
    "                  np.r_[model_freqs[:,0],\n",
    "                        model_freqs[:,1], \n",
    "                        model_freqs[:,2]]]      \n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "\n",
    "    plot_model_tau = np.mod(X[:,0], freqs_dummy.DPi1)\n",
    "    plot_model_tau[plot_model_tau > freqs_dummy.DPi1/2] -=  freqs_dummy.DPi1\n",
    "\n",
    "    axa.scatter(plot_tau, inp_freqs, s=15,\n",
    "            c='royalblue', edgecolor='k', alpha=0.8,\n",
    "               label='$\\\\Delta\\\\Pi_1$: %.2f, $q$: %.2f, $\\\\epsilon_g$: %.2f, $\\\\delta_{\\\\mathrm{rot}}$: %.2f'\n",
    "               %(cand_dpi, cand_q, cand_eps_g, cand_rot))\n",
    "    axa.set_ylim(np.min(inp_freqs)-2, np.max(inp_freqs)+2)\n",
    "    axa.set_ylabel('$\\\\nu$ ($\\\\mu$Hz)', fontsize=16)\n",
    "    axa.set_xlabel('$\\\\tau$ mod $\\\\Delta\\\\Pi_1$', fontsize=16)\n",
    "    axa.set_xlim(-cand_dpi/2, cand_dpi/2)\n",
    "    axa.set_title(label, fontsize=15)\n",
    "    axa.legend(prop={'size': 15})\n",
    "    axa.tick_params(labelsize=15)\n",
    "\n",
    "\n",
    "    axb.scatter(plot_model_tau, X[:,1], s=10, c='r', alpha=0.25, label='Model')\n",
    "    axb.scatter(plot_tau, inp_freqs, s=np.power(prepped_l1_peaks['height'].values, 1.5),\n",
    "             c='royalblue', edgecolor='k', alpha=0.8, label='Observed')\n",
    "    axb.set_ylim(np.min(inp_freqs)-2, np.max(inp_freqs)+2)\n",
    "    axb.set_ylabel('$\\\\nu$ ($\\\\mu$Hz)', fontsize=16)\n",
    "    axb.set_xlabel('$\\\\tau$ mod $\\\\Delta\\\\Pi_1$', fontsize=16)\n",
    "    axb.set_xlim(-cand_dpi/2, cand_dpi/2)\n",
    "    axa.tick_params(labelsize=15)\n",
    "    \n",
    "    ### Calculating the Hungarian loss difference upon removal of specific rotational components ###\n",
    "    \n",
    "    X_no0 = np.c_[np.r_[model_tau[:,1] - freqs_dummy.shift * freqs_dummy.DPi1, \n",
    "                    model_tau[:,2] - freqs_dummy.shift * freqs_dummy.DPi1], \n",
    "              np.r_[model_freqs[:,1], \n",
    "                    model_freqs[:,2]]]\n",
    "    X_nop1 = np.c_[np.r_[model_tau[:,0],\n",
    "                    model_tau[:,2] - freqs_dummy.shift * freqs_dummy.DPi1], \n",
    "              np.r_[model_freqs[:,0],\n",
    "                    model_freqs[:,2]]]\n",
    "    X_non1 = np.c_[np.r_[model_tau[:,0],\n",
    "                    model_tau[:,1] - freqs_dummy.shift * freqs_dummy.DPi1], \n",
    "              np.r_[model_freqs[:,0],\n",
    "                    model_freqs[:,1]]]\n",
    "\n",
    "    X_list = [X, X_no0, X_nop1, X_non1]\n",
    "    condition = ['m=0 Removal', 'm=+1 Removal', 'm=-1 Removal']\n",
    "    pct_diff_vec = []\n",
    "    for i, inp in enumerate(X_list):\n",
    "        c1 = np.vstack((inp[:,0]/freqs_dummy.DPi1, (inp[:,1]-freqs_dummy.numax)/freqs_dummy.delta_nu)).T#(X_t[:,1]-freqs.numax)/freqs.delta_nu )).T\n",
    "        c2 = np.vstack((real_tau/freqs_dummy.DPi1, (inp_freqs-freqs_dummy.numax)/freqs_dummy.delta_nu)).T\n",
    "\n",
    "\n",
    "        tree = KDTree(c1)\n",
    "        nearest_dists, nearest_idx = tree.query(c2, k=1)\n",
    "        kost = np.median(nearest_dists)\n",
    "        if i == 0:\n",
    "            prime_cost = kost\n",
    "        else:\n",
    "            pct_diff = np.abs((kost-prime_cost)*100./prime_cost)\n",
    "            pct_diff_vec.append(np.round(pct_diff, 2))\n",
    "    \n",
    "    axb.set_title('KIC: %d, [$\\\\delta_0$, $\\\\delta_{+1}$, $\\\\delta_{-1}$]: %s' %(idx, pct_diff_vec), fontsize=15)\n",
    "    return pct_diff_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main looping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bopt_rotation(data):\n",
    "    name, row = data\n",
    "    iz, init_dpi, init_q = row['KIC'], row['dpi'], row['q']\n",
    "    \n",
    "    header_df = pd.read_csv(abba_folder + '%d.modes.dat' %iz, \n",
    "                            delim_whitespace=True, header=0, skiprows = 4, nrows=1)\n",
    "    nmx = header_df['fmax'].values[0]\n",
    "    dnu = header_df['dnu'].values[0]\n",
    "    evo = header_df['evo'].values[0]\n",
    "    alpha = header_df['alpha'].values[0]\n",
    "    f0 = header_df['f0_c'].values[0]\n",
    "    eps = np.mod(f0, dnu)/dnu\n",
    "    \n",
    "    print('KIC %d, Init DPi1 %.2f, Init q: %.2f' %(iz, init_dpi, init_q))\n",
    "    if iz in out_file.iloc[:,0].values:\n",
    "        return None\n",
    "        \n",
    "    if eps < 0.5:\n",
    "        eps += 1\n",
    "        \n",
    "    peaks = pd.read_csv(abba_folder + '%d.modes.dat' %iz, \n",
    "                            delim_whitespace=True, header=0, skiprows = 7)\n",
    "    peaks = peaks.rename(columns={'amp': 'height'})\n",
    "    \n",
    "    peaks['linewidth'] = 1/(1*np.pi*peaks['tau']*0.0864)\n",
    "    peaks['weights'] = (peaks['height']/np.sum(peaks['height']))*1000.\n",
    "    \n",
    "    evidence_cut=0.05\n",
    "    \n",
    "    peaks['x'] = ((peaks['freq'] % dnu - eps) / dnu) % 1\n",
    "    # Don't want to include any modes near l=0 or 2s, this is why this and the step in the next cell is performed.\n",
    "    x_range = [(np.minimum(np.min(peaks.loc[peaks['l'] == 0, 'x']), np.min(peaks.loc[peaks['l'] == 2, 'x'])) - 0.05) % 1,\n",
    "               (np.maximum(np.max(peaks.loc[peaks['l'] == 0, 'x']), np.max(peaks.loc[peaks['l'] == 2, 'x'])) + 0.05) % 1]\n",
    "    \n",
    "    l1_peaks = peaks.loc[(peaks.l == 1) | ~np.isfinite(peaks.l), ]\n",
    "    l1_peaks['x'] = ((l1_peaks['freq'] % dnu - eps) / dnu) % 1\n",
    "    \n",
    "    if x_range[0] < x_range[1]:\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] < x_range[1]) | (l1_peaks['x'] > x_range[0]), ] # changed to OR for HeB\n",
    "    else:\n",
    "        l1_peaks = l1_peaks.loc[(l1_peaks['x'] > x_range[1]) & (l1_peaks['x'] < x_range[0]), ] # this is AND for RGB\n",
    "    prepped_l1_peaks = l1_peaks.loc[(l1_peaks['ev1'] > evidence_cut), ]\n",
    "    \n",
    "    try:\n",
    "        pds = pd.read_csv(abba_psd_folder + 'kplr%d.ts.fft.pds.bgcorr' %iz,\n",
    "                              header=None, delim_whitespace=True)\n",
    "    except:\n",
    "        return None\n",
    "    pds.columns = ['frequency', 'power']\n",
    "    # Only keep pds around oscillations\n",
    "    sigmaEnv = (0.59 * (nmx ** 0.9))/2\n",
    "    pds = pds.loc[abs(pds['frequency'].values - nmx) < 3 * sigmaEnv, ]\n",
    "    peaks = peaks.loc[abs(peaks.freq.values - nmx) < 3*sigmaEnv, ]\n",
    "    \n",
    "    l023_peaks = peaks.loc[(peaks.l == 0) | (peaks.l == 2) | (peaks.l == 3), ]\n",
    "    l0_peaks = peaks.loc[(peaks.l==0), ]\n",
    "    l1_peaks = peaks.loc[(peaks.l == 1) | (np.isfinite(peaks.l) == False)]\n",
    "    l2_peaks = peaks.loc[(peaks.l==2), ]\n",
    "    \n",
    "    pds_l023_removed = pds.assign(power = pds.power / fit_model(pds, l023_peaks))\n",
    "    \n",
    "    try:\n",
    "        freqs_class = frequencies.Frequencies(frequency=pds_l023_removed.frequency.values,\n",
    "                                    numax=nmx, \n",
    "                                    delta_nu=dnu, \n",
    "                                    epsilon_p=eps,\n",
    "                                    alpha=alpha)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    inp_freqs = prepped_l1_peaks['freq'].values\n",
    "    if len(inp_freqs) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        loss_list_index = 2 # automatically assume triplet\n",
    "\n",
    "        init_time = timer.time()\n",
    "        best_sol, best_loss, sampled_points, losses = optimize_rotation(init_dpi, init_q, freqs_class, inp_freqs, loss_list_index,\n",
    "                                           weights=prepped_l1_peaks['weights'].values, verbose=False)\n",
    "        print('Time Taken to Optimize Rotation: ', timer.time()-init_time)\n",
    "        if loss_list_index == 0:\n",
    "            rotx = -99\n",
    "        else:\n",
    "            rotx = np.around(best_sol, 3)[3]\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 7))\n",
    "        ax1, ax2 = fig.add_subplot(121), fig.add_subplot(122)\n",
    "        pct_diff_vec = plot_solution(freqs_class, inp_freqs, prepped_l1_peaks,\n",
    "                                     cand_dpi=np.around(best_sol, 3)[0],\n",
    "                      cand_q=np.around(best_sol, 3)[1],\n",
    "                      cand_eps_g=np.around(best_sol, 3)[2],\n",
    "                      cand_rot=rotx, \n",
    "                      rot_index=loss_list_index, \n",
    "                      axa=ax1, axb=ax2,\n",
    "                     label='BOpt Solution', idx=iz)\n",
    "\n",
    "        plt.tight_layout(h_pad=0)\n",
    "        plt.savefig(image_folder + '%d.png' %iz)\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        np.savez_compressed(samples_folder + '%d.npz' %iz,\n",
    "                           kic=iz, samples=sampled_points, loss=losses)\n",
    "\n",
    "        with open(output_file, 'a') as writer:\n",
    "            writer.write(str(int(iz))+','+str(np.around(best_sol, 3)[0])+','+str(np.around(best_sol, 3)[1])+','\\\n",
    "                         +str(np.around(best_sol, 3)[2])+','+str(np.around(rotx, 3))+','+ str(np.around(best_loss, 3)[0])+','\\\n",
    "                         +str(np.round(pct_diff_vec[0], 2))+','+str(np.round(pct_diff_vec[1], 2))+','+str(np.round(pct_diff_vec[2], 2)) +'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the loop in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4)(delayed(bopt_rotation)(i) for i in tqdm(summary_df.iterrows(), total=len(summary_df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
